# app.py
# í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ ëŒ€ì‹œë³´ë“œ (Semantic Scholar + OpenAlex)

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime

from config.journals import (
    TARGET_JOURNALS, EXTENDED_JOURNALS,
    get_all_extended_journals, get_journal_metadata
)
from config.keywords import (
    KEYWORD_EXPANSIONS, RESEARCH_PRESETS,
    expand_keywords
)
from utils.search import search_and_filter
from utils.export import to_csv, to_bibtex, get_summary_stats

st.set_page_config(page_title="ğŸ“š Research Paper Tracker", page_icon="ğŸ“š", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
<style>
    .main-header {font-size: 2rem; font-weight: bold; margin-bottom: 1rem;}
    .journal-badge {background-color: #1f77b4; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem; margin-right: 4px;}
    .tier-badge {background-color: #2ca02c; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem;}
    .source-badge {background-color: #ff7f0e; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem; margin-left: 4px;}
</style>
""", unsafe_allow_html=True)

if "search_results" not in st.session_state:
    st.session_state.search_results = []
if "search_executed" not in st.session_state:
    st.session_state.search_executed = False

keywords = []
selected_expansions = {}
search_keywords = []

with st.sidebar:
    st.markdown("## ğŸ” ê²€ìƒ‰ ì„¤ì •")
    
    # ê²€ìƒ‰ ì†ŒìŠ¤ ì„ íƒ (ìƒˆë¡œ ì¶”ê°€!)
    st.markdown("### ğŸ“¡ ê²€ìƒ‰ ì†ŒìŠ¤")
    search_source = st.radio(
        "API ì„ íƒ",
        ["both", "semantic", "openalex"],
        format_func=lambda x: {
            "both": "ğŸ”„ í†µí•© ê²€ìƒ‰ (ì¶”ì²œ)",
            "semantic": "ğŸ“š Semantic Scholarë§Œ",
            "openalex": "ğŸŒ OpenAlexë§Œ"
        }[x],
        index=0,
        help="OpenAlexê°€ ìµœì‹  ë…¼ë¬¸ ë°˜ì˜ì´ ë” ë¹ ë¦…ë‹ˆë‹¤"
    )
    
    st.markdown("---")
    
    # ê²€ìƒ‰ ëª¨ë“œ
    st.markdown("### ê²€ìƒ‰ ëª¨ë“œ")
    search_mode = st.radio("ê²€ìƒ‰ ë°©ì‹ ì„ íƒ", ["ë‹¨ìˆœ ê²€ìƒ‰", "ìŠ¤ë§ˆíŠ¸ í™•ì¥"], index=0, help="ìŠ¤ë§ˆíŠ¸ í™•ì¥: ìœ ì˜ì–´/ê´€ë ¨ì–´ í¬í•¨ ê²€ìƒ‰")
    
    st.markdown("---")
    st.markdown("### í‚¤ì›Œë“œ ì…ë ¥")
    
    preset_option = st.selectbox("ğŸ“Œ ì €ì¥ëœ ì—°êµ¬ ì£¼ì œ", ["ì§ì ‘ ì…ë ¥"] + list(RESEARCH_PRESETS.keys()))
    
    if preset_option == "ì§ì ‘ ì…ë ¥":
        keyword_input = st.text_input("í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: social media, tourism")
        keywords = [k.strip() for k in keyword_input.split(",") if k.strip()]
    else:
        preset_data = RESEARCH_PRESETS[preset_option]
        st.info(f"ğŸ“ {preset_data['description']}")
        keywords = preset_data["keywords"]
        st.write("**í¬í•¨ í‚¤ì›Œë“œ:**", ", ".join(keywords))
    
    if search_mode == "ìŠ¤ë§ˆíŠ¸ í™•ì¥" and keywords:
        st.markdown("### ğŸ”„ í™•ì¥ëœ í‚¤ì›Œë“œ")
        expanded = expand_keywords(keywords)
        for original, expansions in expanded.items():
            with st.expander(f"ğŸ“ {original}", expanded=True):
                selected = []
                for term in expansions:
                    if st.checkbox(term, value=True, key=f"exp_{original}_{term}"):
                        selected.append(term)
                selected_expansions[original] = selected
        for terms in selected_expansions.values():
            search_keywords.extend(terms)
    else:
        search_keywords = keywords.copy()
    
    st.markdown("---")
    st.markdown("### ğŸ“š ì €ë„ í•„í„°")
    st.markdown("**[Track A] í•µì‹¬ ì €ë„**")
    selected_categories = {}
    for category, data in TARGET_JOURNALS.items():
        selected_categories[category] = st.checkbox(
            f"{data['description']} ({len(data['journals'])}ê°œ)", 
            value=True, 
            key=f"cat_{category}"
        )
    
    st.markdown("**[Track B] í™•ì¥ ì €ë„**")
    include_extended = st.checkbox("ë¦¬ìŠ¤íŠ¸ ì™¸ Q1 ì €ë„ í¬í•¨", value=False)
    
    st.markdown("---")
    st.markdown("### âš™ï¸ í•„í„° ì˜µì…˜")
    col1, col2 = st.columns(2)
    with col1:
        year_start = st.number_input("ì‹œì‘ ì—°ë„", min_value=2000, max_value=2025, value=2015)
    with col2:
        year_end = st.number_input("ì¢…ë£Œ ì—°ë„", min_value=2000, max_value=2026, value=2025)
    
    min_citations = st.slider("ìµœì†Œ ì¸ìš©ìˆ˜", 0, 100, 0)
    max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜", 10, 300, 100)  # ê¸°ë³¸ê°’ 100ìœ¼ë¡œ ì¦ê°€
    
    st.markdown("---")
    search_button = st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True)

# ë©”ì¸ ì˜ì—­
st.markdown('<p class="main-header">ğŸ“š Research Paper Tracker</p>', unsafe_allow_html=True)
st.markdown("Tourism & Physical AI ì—°êµ¬ë¥¼ ìœ„í•œ ë…¼ë¬¸ ìˆ˜ì§‘ ëŒ€ì‹œë³´ë“œ")

if search_button:
    if not search_keywords:
        st.warning("âš ï¸ ê²€ìƒ‰í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        with st.spinner("ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘... (Semantic Scholar + OpenAlex)"):
            try:
                target_journals = []
                for category, selected in selected_categories.items():
                    if selected:
                        target_journals.extend(TARGET_JOURNALS[category]["journals"])
                
                extended_journals = get_all_extended_journals() if include_extended else []
                
                source_name = {"both": "í†µí•©", "semantic": "Semantic Scholar", "openalex": "OpenAlex"}[search_source]
                st.info(f"ğŸ” ê²€ìƒ‰: {', '.join(search_keywords[:3])}{'...' if len(search_keywords) > 3 else ''} | ğŸ“¡ {source_name} | ğŸ“… {year_start}-{year_end}")
                
                results = search_and_filter(
                    keywords=search_keywords,
                    target_journals=target_journals,
                    extended_journals=extended_journals,
                    year_start=int(year_start),
                    year_end=int(year_end),
                    min_citations=int(min_citations),
                    include_extended=include_extended,
                    limit=int(max_results),
                    search_source=search_source
                )
                
                st.session_state.search_results = results
                st.session_state.search_executed = True
                
                if results:
                    # ì†ŒìŠ¤ë³„ í†µê³„
                    ss_count = len([r for r in results if r.get("source") == "Semantic Scholar"])
                    oa_count = len([r for r in results if r.get("source") == "OpenAlex"])
                    st.success(f"âœ… {len(results)}ê°œ ë…¼ë¬¸ ë°œê²¬! (Semantic Scholar: {ss_count}ê°œ, OpenAlex: {oa_count}ê°œ)")
                else:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë‚˜ ì—°ë„ ë²”ìœ„ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.session_state.search_results = []

results = st.session_state.search_results

if results:
    stats = get_summary_stats(results)
    st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
    col1, col2, col3, col4, col5 = st.columns(5)
    col1.metric("ì´ ë…¼ë¬¸ ìˆ˜", stats["total"])
    col2.metric("High Priority", stats["high_priority"])
    col3.metric("Medium Priority", stats["medium_priority"])
    col4.metric("Low Priority", stats.get("low_priority", 0))
    col5.metric("í‰ê·  ì¸ìš©ìˆ˜", stats["avg_citations"])
    
    st.markdown("---")
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ ë…¼ë¬¸ ëª©ë¡", "ğŸ“ˆ ì‹œê°í™”", "ğŸ’¾ ë‚´ë³´ë‚´ê¸°"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        with col1:
            sort_option = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ìš°ì„ ìˆœìœ„ (ê¸°ë³¸)", "ì¸ìš©ìˆ˜ (ë†’ì€ ìˆœ)", "ì—°ë„ (ìµœì‹  ìˆœ)", "ì—°ë„ (ì˜¤ë˜ëœ ìˆœ)"])
        with col2:
            filter_priority = st.multiselect("Priority í•„í„°", ["High", "Medium", "Low"], default=["High", "Medium", "Low"])
        
        sorted_results = [r for r in results if r["priority"] in filter_priority]
        
        if sort_option == "ì¸ìš©ìˆ˜ (ë†’ì€ ìˆœ)":
            sorted_results.sort(key=lambda x: x["citations"], reverse=True)
        elif sort_option == "ì—°ë„ (ìµœì‹  ìˆœ)":
            sorted_results.sort(key=lambda x: x["year"] or 0, reverse=True)
        elif sort_option == "ì—°ë„ (ì˜¤ë˜ëœ ìˆœ)":
            sorted_results.sort(key=lambda x: x["year"] or 9999)
        
        st.markdown(f"**í‘œì‹œ ì¤‘: {len(sorted_results)}ê°œ ë…¼ë¬¸**")
        
        for paper in sorted_results:
            priority_color = {"High": "ğŸŸ¢", "Medium": "ğŸŸ¡", "Low": "ğŸ”µ"}.get(paper["priority"], "âšª")
            
            with st.expander(f"{priority_color} **{paper['title'][:80]}{'...' if len(paper['title']) > 80 else ''}** | {paper['year']} | Cited: {paper['citations']}", expanded=False):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**ì €ì:** {paper['authors']}")
                    st.markdown(f"**ì €ë„:** {paper['venue']}")
                    journal_meta = get_journal_metadata(paper['venue'])
                    if journal_meta.get("IF"):
                        st.markdown(f"<span class='journal-badge'>IF: {journal_meta['IF']}</span><span class='tier-badge'>{journal_meta.get('tier', 'N/A')}</span>", unsafe_allow_html=True)
                with col2:
                    st.markdown(f"**Priority:** {paper['priority']}")
                    st.markdown(f"**Track:** {paper['track']}")
                    st.markdown(f"<span class='source-badge'>{paper.get('source', 'N/A')}</span>", unsafe_allow_html=True)
                
                st.markdown("**ì´ˆë¡:**")
                abstract_text = paper['abstract'] if paper['abstract'] and paper['abstract'] != "Abstract available" else "_ì´ˆë¡ ì—†ìŒ (ì›ë¬¸ì—ì„œ í™•ì¸)_"
                st.markdown(abstract_text)
                
                col1, col2 = st.columns(2)
                if paper['url']:
                    col1.markdown(f"[ğŸ“ ë…¼ë¬¸ ë§í¬]({paper['url']})")
                if paper['pdf_url']:
                    col2.markdown(f"[ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ]({paper['pdf_url']})")
    
    with tab2:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ğŸ“… ì—°ë„ë³„ ë…¼ë¬¸ ìˆ˜")
            year_data = [r["year"] for r in results if r["year"] and r["year"] != "N/A"]
            if year_data:
                year_counts = pd.Series(year_data).value_counts().sort_index()
                fig_year = px.bar(x=year_counts.index, y=year_counts.values, labels={"x": "ì—°ë„", "y": "ë…¼ë¬¸ ìˆ˜"})
                fig_year.update_layout(showlegend=False, height=300)
                st.plotly_chart(fig_year, use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ¯ Priority ë¶„í¬")
            priority_counts = pd.Series([r["priority"] for r in results]).value_counts()
            fig_priority = px.pie(values=priority_counts.values, names=priority_counts.index, color=priority_counts.index, color_discrete_map={"High": "#2ca02c", "Medium": "#ff7f0e", "Low": "#1f77b4"})
            fig_priority.update_layout(height=300)
            st.plotly_chart(fig_priority, use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ğŸ“¡ ê²€ìƒ‰ ì†ŒìŠ¤ ë¶„í¬")
            source_counts = pd.Series([r.get("source", "Unknown") for r in results]).value_counts()
            fig_source = px.pie(values=source_counts.values, names=source_counts.index)
            fig_source.update_layout(height=300)
            st.plotly_chart(fig_source, use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ† ìƒìœ„ ì¸ìš© ë…¼ë¬¸ Top 10")
            top_papers = sorted(results, key=lambda x: x["citations"], reverse=True)[:10]
            if top_papers:
                fig_top = px.bar(
                    x=[p["citations"] for p in top_papers],
                    y=[p["title"][:35] + "..." if len(p["title"]) > 35 else p["title"] for p in top_papers],
                    orientation="h", labels={"x": "ì¸ìš©ìˆ˜", "y": ""}
                )
                fig_top.update_layout(height=350, yaxis={"categoryorder": "total ascending"})
                st.plotly_chart(fig_top, use_container_width=True)
        
        st.markdown("#### ğŸ“š ìƒìœ„ ì €ë„ ë¶„í¬")
        venue_data = [r["venue"] for r in results if r["venue"] and r["venue"] not in ["Unknown", "", "N/A"]]
        if venue_data:
            venue_counts = pd.Series(venue_data).value_counts().head(15)
            fig_venue = px.bar(x=venue_counts.values, y=venue_counts.index, orientation="h", labels={"x": "ë…¼ë¬¸ ìˆ˜", "y": ""})
            fig_venue.update_layout(height=450, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig_venue, use_container_width=True)
    
    with tab3:
        st.markdown("#### ğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
        col1, col2 = st.columns(2)
        with col1:
            csv_data = to_csv(results)
            st.download_button(label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ", data=csv_data, file_name=f"papers_{datetime.now().strftime('%Y%m%d')}.csv", mime="text/csv", use_container_width=True)
        with col2:
            bibtex_data = to_bibtex(results)
            st.download_button(label="ğŸ“¥ BibTeX ë‹¤ìš´ë¡œë“œ", data=bibtex_data, file_name=f"papers_{datetime.now().strftime('%Y%m%d')}.bib", mime="text/plain", use_container_width=True)

else:
    if not st.session_state.search_executed:
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œì™€ í•„í„°ë¥¼ ì„¤ì •í•œ í›„ 'ê²€ìƒ‰ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    with st.expander("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ", expanded=True):
        st.markdown("""
        ### ìƒˆë¡œìš´ ê¸°ëŠ¥ âœ¨
        - **í†µí•© ê²€ìƒ‰**: Semantic Scholar + OpenAlex ë™ì‹œ ê²€ìƒ‰
        - **OpenAlex**: ìµœì‹  ë…¼ë¬¸ (2025ë…„ í¬í•¨) ë¹ ë¥¸ ë°˜ì˜
        - **ìµœëŒ€ 300ê°œ** ë…¼ë¬¸ê¹Œì§€ ê²€ìƒ‰ ê°€ëŠ¥
        
        ### ê²€ìƒ‰ ì†ŒìŠ¤ ë¹„êµ
        | ì†ŒìŠ¤ | ì¥ì  |
        |------|------|
        | Semantic Scholar | ì¸ìš© ë¶„ì„ ìš°ìˆ˜, ì´ˆë¡ ì œê³µ |
        | OpenAlex | ìµœì‹  ë…¼ë¬¸ ë¹ ë¦„, ë” ë„“ì€ ì»¤ë²„ë¦¬ì§€ |
        | í†µí•© ê²€ìƒ‰ | ë‘ ì†ŒìŠ¤ ì¥ì  ê²°í•© (ì¶”ì²œ) |
        """)
    
    st.markdown("### ğŸ“Œ ì €ì¥ëœ ì—°êµ¬ ì£¼ì œ í”„ë¦¬ì…‹")
    for name, data in RESEARCH_PRESETS.items():
        with st.expander(f"ğŸ”– {name}"):
            st.markdown(f"**ì„¤ëª…:** {data['description']}")
            st.markdown(f"**í‚¤ì›Œë“œ:** {', '.join(data['keywords'])}")

st.markdown("---")
st.markdown("<div style='text-align: center; color: #666;'>ğŸ“š Research Paper Tracker | Semantic Scholar + OpenAlex API</div>", unsafe_allow_html=True)
