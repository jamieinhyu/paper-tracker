# app.py
# í•™ìˆ  ë…¼ë¬¸ ê²€ìƒ‰ ëŒ€ì‹œë³´ë“œ

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime

from config.journals import (
    TARGET_JOURNALS, EXTENDED_JOURNALS, JOURNAL_METADATA,
    get_all_target_journals, get_all_extended_journals, get_journal_metadata
)
from config.keywords import (
    KEYWORD_EXPANSIONS, RESEARCH_PRESETS, CONTEXT_KEYWORDS,
    expand_keywords, get_all_expanded_terms
)
from utils.search import search_and_filter, search_papers
from utils.export import to_csv, to_bibtex, get_summary_stats

st.set_page_config(page_title="ğŸ“š Research Paper Tracker", page_icon="ğŸ“š", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
<style>
    .main-header {font-size: 2rem; font-weight: bold; margin-bottom: 1rem;}
    .journal-badge {background-color: #1f77b4; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem; margin-right: 4px;}
    .tier-badge {background-color: #2ca02c; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.8rem;}
</style>
""", unsafe_allow_html=True)

if "search_results" not in st.session_state:
    st.session_state.search_results = []
if "search_executed" not in st.session_state:
    st.session_state.search_executed = False
if "raw_api_results" not in st.session_state:
    st.session_state.raw_api_results = []

keywords = []
selected_expansions = {}
search_keywords = []

with st.sidebar:
    st.markdown("## ğŸ” ê²€ìƒ‰ ì„¤ì •")
    st.markdown("### ê²€ìƒ‰ ëª¨ë“œ")
    search_mode = st.radio("ê²€ìƒ‰ ë°©ì‹ ì„ íƒ", ["ë‹¨ìˆœ ê²€ìƒ‰", "ìŠ¤ë§ˆíŠ¸ í™•ì¥"], index=1, help="ìŠ¤ë§ˆíŠ¸ í™•ì¥: ìœ ì˜ì–´/ê´€ë ¨ì–´ í¬í•¨ ê²€ìƒ‰")
    
    st.markdown("---")
    st.markdown("### í‚¤ì›Œë“œ ì…ë ¥")
    
    preset_option = st.selectbox("ğŸ“Œ ì €ì¥ëœ ì—°êµ¬ ì£¼ì œ", ["ì§ì ‘ ì…ë ¥"] + list(RESEARCH_PRESETS.keys()), help="ìì£¼ ì‚¬ìš©í•˜ëŠ” ê²€ìƒ‰ì–´ ì¡°í•©")
    
    if preset_option == "ì§ì ‘ ì…ë ¥":
        keyword_input = st.text_input("í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: Social Robot, Tourism, AI")
        keywords = [k.strip() for k in keyword_input.split(",") if k.strip()]
    else:
        preset_data = RESEARCH_PRESETS[preset_option]
        st.info(f"ğŸ“ {preset_data['description']}")
        keywords = preset_data["keywords"]
        st.write("**í¬í•¨ í‚¤ì›Œë“œ:**", ", ".join(keywords))
    
    if search_mode == "ìŠ¤ë§ˆíŠ¸ í™•ì¥" and keywords:
        st.markdown("### ğŸ”„ í™•ì¥ëœ í‚¤ì›Œë“œ")
        expanded = expand_keywords(keywords)
        for original, expansions in expanded.items():
            with st.expander(f"ğŸ“ {original}", expanded=True):
                selected = []
                for term in expansions:
                    if st.checkbox(term, value=True, key=f"exp_{original}_{term}"):
                        selected.append(term)
                selected_expansions[original] = selected
        for terms in selected_expansions.values():
            search_keywords.extend(terms)
        if search_keywords:
            st.markdown("**ê²€ìƒ‰ ì¿¼ë¦¬ ë¯¸ë¦¬ë³´ê¸°:**")
            st.code(" OR ".join(search_keywords[:5]) + ("..." if len(search_keywords) > 5 else ""))
    else:
        search_keywords = keywords.copy()
    
    st.markdown("---")
    st.markdown("### ğŸ“š ì €ë„ í•„í„°")
    st.markdown("**[Track A] í•µì‹¬ ì €ë„**")
    selected_categories = {}
    for category, data in TARGET_JOURNALS.items():
        selected_categories[category] = st.checkbox(f"{data['description']} ({len(data['journals'])}ê°œ)", value=True, key=f"cat_{category}")
    
    st.markdown("**[Track B] í™•ì¥ ì €ë„**")
    include_extended = st.checkbox("ë¦¬ìŠ¤íŠ¸ ì™¸ Q1 ì €ë„ í¬í•¨", value=False)
    
    st.markdown("---")
    st.markdown("### âš™ï¸ í•„í„° ì˜µì…˜")
    col1, col2 = st.columns(2)
    with col1:
        year_start = st.number_input("ì‹œì‘ ì—°ë„", min_value=2000, max_value=2025, value=2015)
    with col2:
        year_end = st.number_input("ì¢…ë£Œ ì—°ë„", min_value=2000, max_value=2025, value=2025)
    min_citations = st.slider("ìµœì†Œ ì¸ìš©ìˆ˜", 0, 100, 0)
    max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜", 10, 200, 50)
    
    st.markdown("---")
    
    # ë””ë²„ê¹… ëª¨ë“œ ì¶”ê°€
    debug_mode = st.checkbox("ğŸ”§ ë””ë²„ê¹… ëª¨ë“œ (API ì›ë³¸ ê²°ê³¼ ë³´ê¸°)", value=False)
    
    st.markdown("---")
    search_button = st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True)

st.markdown('<p class="main-header">ğŸ“š Research Paper Tracker</p>', unsafe_allow_html=True)
st.markdown("Tourism & Physical AI ì—°êµ¬ë¥¼ ìœ„í•œ ë…¼ë¬¸ ìˆ˜ì§‘ ëŒ€ì‹œë³´ë“œ")

if search_button:
    if not search_keywords:
        st.warning("âš ï¸ ê²€ìƒ‰í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ í”„ë¦¬ì…‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
            try:
                target_journals = []
                for category, selected in selected_categories.items():
                    if selected:
                        target_journals.extend(TARGET_JOURNALS[category]["journals"])
                
                extended_journals = get_all_extended_journals() if include_extended else []
                
                st.info(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(search_keywords[:5])}{'...' if len(search_keywords) > 5 else ''}")
                st.info(f"ğŸ“š íƒ€ê²Ÿ ì €ë„ ìˆ˜: {len(target_journals)}ê°œ | ğŸ“… ê²€ìƒ‰ ê¸°ê°„: {year_start}-{year_end}")
                
                # API ì›ë³¸ ê²°ê³¼ ì €ì¥ (ë””ë²„ê¹…ìš©)
                query = " OR ".join(search_keywords)
                raw_papers = search_papers(
                    query=query,
                    year_start=int(year_start),
                    year_end=int(year_end),
                    min_citations=int(min_citations),
                    limit=int(max_results)
                )
                st.session_state.raw_api_results = raw_papers
                
                # í•„í„°ë§ëœ ê²°ê³¼
                results = search_and_filter(
                    keywords=search_keywords,
                    target_journals=target_journals,
                    extended_journals=extended_journals,
                    year_start=int(year_start),
                    year_end=int(year_end),
                    min_citations=int(min_citations),
                    include_extended=include_extended,
                    limit=int(max_results)
                )
                
                st.session_state.search_results = results
                st.session_state.search_executed = True
                
                # ë””ë²„ê¹… ì •ë³´
                st.info(f"ğŸ“Š API ì›ë³¸ ê²°ê³¼: {len(raw_papers)}ê°œ â†’ í•„í„°ë§ í›„: {len(results)}ê°œ")
                
                if results:
                    st.success(f"âœ… {len(results)}ê°œì˜ ë…¼ë¬¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                else:
                    st.warning("âš ï¸ í•„í„°ë§ í›„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê¹… ëª¨ë“œë¥¼ ì¼œì„œ API ì›ë³¸ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.session_state.search_results = []

# ë””ë²„ê¹… ëª¨ë“œ: API ì›ë³¸ ê²°ê³¼ í‘œì‹œ
if debug_mode and st.session_state.raw_api_results:
    st.markdown("### ğŸ”§ ë””ë²„ê¹…: API ì›ë³¸ ê²°ê³¼")
    st.markdown(f"**APIê°€ ë°˜í™˜í•œ ë…¼ë¬¸ ìˆ˜:** {len(st.session_state.raw_api_results)}ê°œ")
    
    st.markdown("**ì €ë„(venue) ëª©ë¡ (API ë°˜í™˜ê°’):**")
    venues = [p.get("venue", "N/A") for p in st.session_state.raw_api_results[:20]]
    for i, v in enumerate(venues):
        st.text(f"{i+1}. {v}")
    
    with st.expander("ğŸ“‹ ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ)"):
        for i, paper in enumerate(st.session_state.raw_api_results[:3]):
            st.json({
                "title": paper.get("title"),
                "venue": paper.get("venue"),
                "year": paper.get("year"),
                "citationCount": paper.get("citationCount")
            })

results = st.session_state.search_results

if results:
    stats = get_summary_stats(results)
    st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì´ ë…¼ë¬¸ ìˆ˜", stats["total"])
    col2.metric("High Priority", stats["high_priority"])
    col3.metric("Medium Priority", stats["medium_priority"])
    col4.metric("í‰ê·  ì¸ìš©ìˆ˜", stats["avg_citations"])
    
    st.markdown("---")
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ ë…¼ë¬¸ ëª©ë¡", "ğŸ“ˆ ì‹œê°í™”", "ğŸ’¾ ë‚´ë³´ë‚´ê¸°"])
    
    with tab1:
        sort_option = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ìš°ì„ ìˆœìœ„ (ê¸°ë³¸)", "ì¸ìš©ìˆ˜ (ë†’ì€ ìˆœ)", "ì—°ë„ (ìµœì‹  ìˆœ)", "ì—°ë„ (ì˜¤ë˜ëœ ìˆœ)"])
        sorted_results = results.copy()
        if sort_option == "ì¸ìš©ìˆ˜ (ë†’ì€ ìˆœ)":
            sorted_results.sort(key=lambda x: x["citations"], reverse=True)
        elif sort_option == "ì—°ë„ (ìµœì‹  ìˆœ)":
            sorted_results.sort(key=lambda x: x["year"] or 0, reverse=True)
        elif sort_option == "ì—°ë„ (ì˜¤ë˜ëœ ìˆœ)":
            sorted_results.sort(key=lambda x: x["year"] or 9999)
        
        for paper in sorted_results:
            with st.expander(f"**{paper['title'][:80]}{'...' if len(paper['title']) > 80 else ''}** | {paper['year']} | Cited: {paper['citations']}", expanded=False):
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"**ì €ì:** {paper['authors']}")
                    st.markdown(f"**ì €ë„:** {paper['venue']}")
                    journal_meta = get_journal_metadata(paper['venue'])
                    if journal_meta.get("IF"):
                        st.markdown(f"<span class='journal-badge'>IF: {journal_meta['IF']}</span><span class='tier-badge'>{journal_meta.get('tier', 'N/A')}</span>", unsafe_allow_html=True)
                with col2:
                    st.markdown(f"**Priority:** {paper['priority']}")
                    st.markdown(f"**Track:** {paper['track']}")
                st.markdown("**ì´ˆë¡:**")
                st.markdown(paper['abstract'] if paper['abstract'] else "_ì´ˆë¡ ì—†ìŒ_")
                if paper['url']:
                    st.markdown(f"[ğŸ“ ë…¼ë¬¸ ë§í¬]({paper['url']})")
                if paper['pdf_url']:
                    st.markdown(f"[ğŸ“¥ PDF ë‹¤ìš´ë¡œë“œ]({paper['pdf_url']})")
    
    with tab2:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### ğŸ“… ì—°ë„ë³„ ë…¼ë¬¸ ìˆ˜")
            year_data = [r["year"] for r in results if r["year"]]
            if year_data:
                year_counts = pd.Series(year_data).value_counts().sort_index()
                fig_year = px.bar(x=year_counts.index, y=year_counts.values, labels={"x": "ì—°ë„", "y": "ë…¼ë¬¸ ìˆ˜"})
                fig_year.update_layout(showlegend=False, height=300)
                st.plotly_chart(fig_year, use_container_width=True)
        with col2:
            st.markdown("#### ğŸ¯ Priority ë¶„í¬")
            priority_data = [r["priority"] for r in results]
            if priority_data:
                priority_counts = pd.Series(priority_data).value_counts()
                fig_priority = px.pie(values=priority_counts.values, names=priority_counts.index)
                fig_priority.update_layout(height=300)
                st.plotly_chart(fig_priority, use_container_width=True)
        
        st.markdown("#### ğŸ‘¤ ìƒìœ„ ì¸ìš© ë…¼ë¬¸ Top 10")
        top_papers = sorted(results, key=lambda x: x["citations"], reverse=True)[:10]
        if top_papers:
            fig_top = px.bar(x=[p["citations"] for p in top_papers], y=[p["title"][:40] + "..." if len(p["title"]) > 40 else p["title"] for p in top_papers], orientation="h", labels={"x": "ì¸ìš©ìˆ˜", "y": "ë…¼ë¬¸"})
            fig_top.update_layout(height=400, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig_top, use_container_width=True)
    
    with tab3:
        st.markdown("#### ğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**CSV í˜•ì‹**")
            csv_data = to_csv(results)
            st.download_button(label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ", data=csv_data, file_name=f"papers_{datetime.now().strftime('%Y%m%d')}.csv", mime="text/csv", use_container_width=True)
        with col2:
            st.markdown("**BibTeX í˜•ì‹**")
            bibtex_data = to_bibtex(results)
            st.download_button(label="ğŸ“¥ BibTeX ë‹¤ìš´ë¡œë“œ", data=bibtex_data, file_name=f"papers_{datetime.now().strftime('%Y%m%d')}.bib", mime="text/plain", use_container_width=True)

else:
    if not st.session_state.search_executed:
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œì™€ í•„í„°ë¥¼ ì„¤ì •í•œ í›„ 'ê²€ìƒ‰ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    with st.expander("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ", expanded=True):
        st.markdown("""
        ### ê¸°ëŠ¥ ì†Œê°œ
        **1. ê²€ìƒ‰ ëª¨ë“œ** - ë‹¨ìˆœ ê²€ìƒ‰ / ìŠ¤ë§ˆíŠ¸ í™•ì¥ (ìœ ì˜ì–´ í¬í•¨)
        **2. ì €ë„ í•„í„°** - Track A (í•µì‹¬ ì €ë„) / Track B (í™•ì¥ ì €ë„)
        **3. ê²°ê³¼ í‘œì‹œ** - High/Medium/Low Priority
        **4. ë‚´ë³´ë‚´ê¸°** - CSV, BibTeX
        **5. ë””ë²„ê¹… ëª¨ë“œ** - API ì›ë³¸ ê²°ê³¼ í™•ì¸ ê°€ëŠ¥
        """)
    
    st.markdown("### ğŸ“Œ ì €ì¥ëœ ì—°êµ¬ ì£¼ì œ í”„ë¦¬ì…‹")
    for name, data in RESEARCH_PRESETS.items():
        with st.expander(f"ğŸ”– {name}"):
            st.markdown(f"**ì„¤ëª…:** {data['description']}")
            st.markdown(f"**í‚¤ì›Œë“œ:** {', '.join(data['keywords'])}")

st.markdown("---")
st.markdown("<div style='text-align: center; color: #666;'>ğŸ“š Research Paper Tracker | Powered by Semantic Scholar API</div>", unsafe_allow_html=True)
